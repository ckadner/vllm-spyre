# --8<-- [start:supported-model-runtime-configurations]

# List of supported runtime configurations:
#  - platform: [x86_64|s390x|ppc64le] amd64, zOS, PowerPC
#  - cb: True: continuous batching mode; False: static batching mode
#  - tp_size: [1|2|4|8|16] tensor parallel size
#  - warmup_shapes := [(fixed_prompt_length, max_new_tokens, batch_size)] if cb: True
#  - max_model_len: context length
#  - max_num_seqs: number of sequences in a batch (per instance)
#  - num_blocks: number of KV cache blocks
runtime_configs:
  - model: "ibm-ai-platform/micro-g3.3-8b-instruct-1b"
    configs: [
      { platform: "x86_64", cb: False, tp_size: 1, warmup_shapes: [[64, 20, 4], [128, 20, 2]] },
      { platform: "x86_64", cb: False, tp_size: 1, warmup_shapes: [[256, 20, 1]] },
      { platform: "x86_64", cb: False, tp_size: 2, warmup_shapes: [[64, 20, 4]] },
      { platform: "x86_64", cb: False, tp_size: 4, warmup_shapes: [[64, 20, 4]] },
      { platform: "x86_64", cb: False, tp_size: 8, warmup_shapes: [[64, 20, 4]] },
      { platform: "x86_64", cb: True,  tp_size: 1, max_model_len: 128, max_num_seqs: 2, num_blocks:  4 },
      { platform: "x86_64", cb: True,  tp_size: 1, max_model_len: 128, max_num_seqs: 2, num_blocks:  8 },
      { platform: "x86_64", cb: True,  tp_size: 1, max_model_len: 128, max_num_seqs: 4, num_blocks:  0 },
      { platform: "x86_64", cb: True,  tp_size: 1, max_model_len: 128, max_num_seqs: 4, num_blocks:  4 },
      { platform: "x86_64", cb: True,  tp_size: 1, max_model_len: 128, max_num_seqs: 4, num_blocks:  8 },
      { platform: "x86_64", cb: True,  tp_size: 1, max_model_len: 192, max_num_seqs: 2, num_blocks: 16 },
      { platform: "x86_64", cb: True,  tp_size: 1, max_model_len: 192, max_num_seqs: 3, num_blocks: 16 },
      { platform: "x86_64", cb: True,  tp_size: 1, max_model_len: 256, max_num_seqs: 4, num_blocks:  0 },
      { platform: "x86_64", cb: True,  tp_size: 2, max_model_len: 256, max_num_seqs: 4, num_blocks:  0 },
      { platform: "x86_64", cb: True,  tp_size: 4, max_model_len: 256, max_num_seqs: 4, num_blocks:  0 },
      { platform: "x86_64", cb: True,  tp_size: 8, max_model_len: 256, max_num_seqs: 4, num_blocks:  0 },
    ]
  - model: "ibm-ai-platform/micro-g3.3-8b-instruct-1b-FP8"
    configs: [
      { platform: "x86_64", cb: False, tp_size: 1, warmup_shapes: [[64, 20, 4], [128, 20, 2]] },
      { platform: "x86_64", cb: False, tp_size: 2, warmup_shapes: [[64, 20, 4]] },
      { platform: "x86_64", cb: False, tp_size: 4, warmup_shapes: [[64, 20, 4]] },
      { platform: "x86_64", cb: False, tp_size: 8, warmup_shapes: [[64, 20, 4]] },
      { platform: "x86_64", cb: True,  tp_size: 1, max_model_len: 128, max_num_seqs: 2, num_blocks: 4 },
      { platform: "x86_64", cb: True,  tp_size: 1, max_model_len: 128, max_num_seqs: 2, num_blocks: 8 },
      { platform: "x86_64", cb: True,  tp_size: 1, max_model_len: 128, max_num_seqs: 4, num_blocks: 4 },
      { platform: "x86_64", cb: True,  tp_size: 1, max_model_len: 128, max_num_seqs: 4, num_blocks: 8 },
      { platform: "x86_64", cb: True,  tp_size: 1, max_model_len: 192, max_num_seqs: 2, num_blocks: 16 },
      { platform: "x86_64", cb: True,  tp_size: 1, max_model_len: 192, max_num_seqs: 3, num_blocks: 16 },
      { platform: "x86_64", cb: True,  tp_size: 1, max_model_len: 256, max_num_seqs: 4, num_blocks: 0 },
      { platform: "x86_64", cb: True,  tp_size: 2, max_model_len: 256, max_num_seqs: 4, num_blocks: 0 },
      { platform: "x86_64", cb: True,  tp_size: 4, max_model_len: 256, max_num_seqs: 4, num_blocks: 0 },
      { platform: "x86_64", cb: True,  tp_size: 8, max_model_len: 256, max_num_seqs: 4, num_blocks: 0 },
    ]
  - model: "ibm-granite/granite-3.3-8b-instruct"
    configs: [
      { platform: "x86_64",   cb: True,  tp_size: 4, max_model_len: 2048, max_num_seqs: 4 },
      { platform: "x86_64",   cb: True,  tp_size: 4, max_model_len: 4096, max_num_seqs: 4 },
      { platform: "x86_64",   cb: True,  tp_size: 4, max_model_len: 8192, max_num_seqs: 4 },
      { platform: "s390x",   cb: True,  tp_size: 4, max_model_len: 8192, max_num_seqs: 4 },
      { platform: "s390x",   cb: False, tp_size: 4, warmup_shapes: [[ 7168, 1024, 1 ]] },
      { platform: "ppc64le", cb: False, tp_size: 1, warmup_shapes: [[2048, 1024, 16]] },
      { platform: "ppc64le", cb: False, tp_size: 4, warmup_shapes: [[2048, 1024, 16]] },
      { platform: "ppc64le", cb: False, tp_size: 4, warmup_shapes: [[6144, 2048, 1]] },
      { platform: "ppc64le", cb: True,  tp_size: 1, max_model_len: 3072, max_num_seqs: 16 },

      # Decoders: tested on x86 amd64 with max new tokens=128 (Eval-and-Perf/release_testing)
      #Configuration
      #Hardware/TP 	     Precision 	Prompt length(input size) 	                Batch Size 	        Notes
      #AIU/TP=[4,8] 	 float16 	[128, 256, 512, 1024, 2048, 4096, 8192] 	[1, 2, 4, 8, 16] 	vLLM batching type: Continuous
      #GPU H100/L40S/[1] float16 	[128, 256, 512, 1024, 2048, 4096, 8192] 	[1, 2, 4, 8, 16] 	vLLM batching type: Continuous
      #AIU/TP=[4,8]      float8 	[128, 256, 512, 1024, 2048, 4096, 8192] 	[1, 2, 4, 8, 16] 	vLLM batching type: Static
      #GPU H100/L40S/[1] float8 	[128, 256, 512, 1024, 2048, 4096, 8192] 	[1, 2, 4, 8, 16] 	vLLM batching type: Static
    ]
  - model: "ibm-granite/granite-3.3-8b-instruct-FP8" #  "-FP8" ?
    configs: [
      #{ platform: "s390x", cb: True,  tp_size: 4, max_model_len: 8192, max_num_seqs: 4 },     # FUTURE
      #{ platform: "s390x", cb: True,  tp_size: 4, max_model_len: 16384, max_num_seqs: 4 },    # FUTURE
      #{ platform: "s390x", cb: True,  tp_size: 4, max_model_len: 32768, max_num_seqs: 4 },    # FUTURE
      #{ platform: "ppc64le", cb: True,  tp_size: 1, max_model_len: 3072, max_num_seqs: 16 },  # FUTURE
      #{ platform: "ppc64le", cb: True,  tp_size: 4, max_model_len: 8192, max_num_seqs: 4 },   # FUTURE
      #{ platform: "ppc64le", cb: True,  tp_size: 4, max_model_len: 32768, max_num_seqs: 4 },  # FUTURE
    ]
  - model: "sentence-transformers/all-roberta-large-v1"
    configs: [
      { platform: "x86_64", cb: False, tp_size: 1, warmup_shapes: [[64, 0, 4], [64, 0, 8], [128, 0, 4], [128, 0, 8]] },
    ]
# --8<-- [end:supported-model-runtime-configurations]


